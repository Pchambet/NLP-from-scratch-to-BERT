# ðŸ§  L'OdyssÃ©e du NLP : Du Chaos vers le Sens

> *"Le langage est la source des malentendus."* â€” Antoine de Saint-ExupÃ©ry.
>
> Mais pour une machine, le langage n'est mÃªme pas un malentendu. C'est juste du bruit. Une suite inintelligible d'octets. Ce projet raconte l'histoire de comment nous avons appris aux machines Ã  voir Ã  travers ce bruit, Ã  dÃ©couvrir des structures, et finalement, Ã  comprendre le sens.

---

## ðŸ—ºï¸ La Carte du Voyage

Ce dÃ©pÃ´t n'est pas juste une collection de scripts. C'est une progression logique, une ascension en quatre Ã©tapes vers l'intelligence artificielle moderner.

### ðŸŒ‘ Chapitre 1 : L'Atome (TP1 â€” PrÃ©traitement)
Avant de comprendre une phrase, il faut isoler ses composants. C'est l'Ã©tape de la **Tokenisation**.
Ici, nous faisons exploser le texte. Nous nettoyons le bruit (ponctuation, majuscules), nous jetons ce qui est inutile (Stopwords), et nous cherchons la racine de chaque mot (Stemming & Lemmatisation).
ðŸ‘‰ *Objectif : Transformer un flux de caractÃ¨res informe en une sÃ©quence d'unitÃ©s logiques.*

### ðŸ“Š Chapitre 2 : La Matrice (TP2 â€” BOW & TF-IDF)
Maintenant que nous avons des mots, comment les faire comprendre Ã  un ordinateur qui ne parle que des mathÃ©matiques ? Nous les comptons.
Avec le **Bag of Words**, nous transformons chaque texte en un vecteur immense. Avec le **TF-IDF**, nous donnons du poids Ã  la raretÃ© : un mot commun comme "le" s'efface, tandis qu'un mot unique comme "trous noir" brille de mille feux.
ðŸ‘‰ *Objectif : Transformer la littÃ©rature en statistique pour classifier des emails (Spam vs Ham).*

### ðŸŒŒ Chapitre 3 : La GÃ©omÃ©trie (TP3 â€” Word2Vec & FastText)
Les statistiques ne suffisent pas. Dans le Bag of Words, "Roi" et "Reine" sont aussi diffÃ©rents que "Roi" et "Chaise". Ils sont juste des colonnes diffÃ©rentes.
Ici, nous entrons dans l'Ã¨re des **Embeddings**. Nous projetons les mots dans un espace vectoriel dense. Dans cet espace, la distance a un sens. La magie opÃ¨re : `Vecteur(Roi) - Vecteur(Homme) + Vecteur(Femme) â‰ˆ Vecteur(Reine)`.
ðŸ‘‰ *Objectif : Capturer la sÃ©mantique et les analogies grÃ¢ce Ã  la gÃ©omÃ©trie spatiale.*

### ðŸ§  Chapitre 4 : L'Esprit (TP4 â€” BERT)
Nous avons l'atome, la statistique et la gÃ©omÃ©trie. Mais il manquait le **contexte**.
Jusqu'Ã  maintenant, le mot "banque" avait le mÃªme vecteur qu'il s'agisse d'une "banque finance" ou d'un "banc de poissons". Avec **BERT** (Bidirectional Encoder Representations from Transformers), le modÃ¨le lit toute la phrase d'un coup. Il comprend les nuances. Il a "lu" tout WikipÃ©dia. Il sait.
ðŸ‘‰ *Objectif : Utiliser le Transfer Learning pour atteindre des sommets de performance avec peu de donnÃ©es.*

---

## ðŸ› ï¸ Le Laboratoire (Installation)

Pour reproduire ces expÃ©riences, vous avez besoin de votre propre laboratoire.

### 1. PrÃ©paration
Assurez-vous d'avoir Python installÃ©. Clonez ce dÃ©pÃ´t, puis installez les dÃ©pendances :

```bash
# La mÃ©thode moderne (avec uv)
uv run jupyter lab

# Ou la mÃ©thode classique
pip install pandas numpy nltk scikit-learn gensim matplotlib seaborn transformers datasets torch accelerate
jupyter lab
```

### 2. VÃ©rification
Nous avons inclus un script pour valider que votre environnement est prÃªt :

```bash
python verify_env.py
```

### 3. Exploration
Ouvrez le dossier `Solutions/`. Les notebooks sont numÃ©rotÃ©s pour suivre l'histoire dans l'ordre.
Chaque notebook est **autonome** : les rÃ©sultats sont dÃ©jÃ  calculÃ©s et visibles, mais vous pouvez tout rÃ©-exÃ©cuter.

---

## ðŸ“‚ Organisation du DÃ©pÃ´t

```
.
â”œâ”€â”€ Solutions/               # Le cÅ“ur du projet (Les 4 Chapitres)
â”‚   â”œâ”€â”€ TP1_Pretraitement.ipynb
â”‚   â”œâ”€â”€ TP2_BOW_TFIDF.ipynb
â”‚   â”œâ”€â”€ TP3_Word2Vec_FastText.ipynb
â”‚   â””â”€â”€ TP4_BERT.ipynb
â”‚
â”œâ”€â”€ data/                    # La matiÃ¨re premiÃ¨re
â”‚   â”œâ”€â”€ alice_wonderland.txt
â”‚   â”œâ”€â”€ spam.csv
â”‚   â””â”€â”€ (autres datasets...)
â”‚
â””â”€â”€ verify_env.py            # Le filet de sÃ©curitÃ©
```

---

> *"Toute technologie suffisamment avancÃ©e est indiscernable de la magie."* â€” Arthur C. Clarke.
>
> Bienvenue dans la magie du NLP.
